# 中文训练数据集

## **分类数据集**

今日头条分类数据集

数据规模：共38万条，分布于15个分类中。

{% embed url="https://github.com/napoler/toutiao-text-classfication-dataset" %}

**清华新闻分类语料**

数据量：74万篇新闻文档（2.19 GB）

{% embed url="http://thuctc.thunlp.org/\#%E8%8E%B7%E5%8F%96%E9%93%BE%E6%8E%A5" %}

**中科大新闻分类语料库**

情感/观点/评论 倾向性分析

## **实体识别&词性标注**

**微博实体识别**

{% embed url="https://github.com/hltcoe/golden-horse" %}

**boson数据**

包含6种实体类型。

{% embed url="https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/boson" %}

**人民日报数据集**

\*\*\*\*[**https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/renMinRiBao**](https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/renMinRiBao)\*\*\*\*

链接: [https://pan.baidu.com/s/1aTWJqLyUqDpkaNreGy3nsQ](https://pan.baidu.com/s/1aTWJqLyUqDpkaNreGy3nsQ) 提取码: x33b 复制这段内容后打开百度网盘手机App，操作更方便哦

**MSRA微软亚洲研究院数据集**

5 万多条中文命名实体识别标注数据（包括地点、机构、人物）

\*\*\*\*[**https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/MSRA**](https://github.com/InsaneLife/ChineseNLPCorpus/tree/master/NER/MSRA)\*\*\*\*

**SIGHAN Bakeoff 2005：**一共有四个数据集，包含繁体中文和简体中文，下面是简体中文分词数据。

{% embed url="http://sighan.cs.uchicago.edu/bakeoff2005/" %}

{% embed url="http://sighan.cs.uchicago.edu/bakeoff2005/" %}

\*\*\*\*

## 中文NLP数据集

 [https://github.com/IceFlameWorm/NLP\_Datasets](https://github.com/IceFlameWorm/NLP_Datasets)

### 已收录数据集

#### ATEC语义相似度学习赛数据集

比赛链接：[https://dc.cloud.alipay.com/index\#/topic/ranking?id=8](https://dc.cloud.alipay.com/index#/topic/ranking?id=8)  
数据集类型：语义相似度  
保存目录：`ATEC`

#### CCKS 2018 微众银行智能客服问句匹配大赛数据集

比赛链接：[https://biendata.com/competition/CCKS2018\_3/leaderboard/](https://biendata.com/competition/CCKS2018_3/leaderboard/)  
数据集类型：语义相似度  
保存目录：`CCKS_2018_3`

#### ATEC + CCKS 2018 组合数据集

由于ATEC比赛和CCKS 2018比赛提供的语料都是互金客服场景下的语料，所以把两个数据集的语料合并到了一起，基于分层抽样划分了出了训练集、验证集和测试集，其中：

* 训练集、验证集和测试集的正类比例均为34%左右
* 训练集：约24W样本
* 验证集：1W样本
* 测试集：1W样本

数据集类型：语义相似度  
保存目录：ATEC\_CCKS

#### 哈工大BQ\_corpus数据集

数据集地址：[http://icrc.hitsz.edu.cn/info/1037/1162.htm](http://icrc.hitsz.edu.cn/info/1037/1162.htm)  
数据集类型：语义相似度  
保存目录：`BQ_corpus`

#### 哈工大LCQMC数据集

数据集地址：[http://icrc.hitsz.edu.cn/Article/show/171.html](http://icrc.hitsz.edu.cn/Article/show/171.html)  
数据集类型：语义相似度  
保存目录：`LCQMC`

\*\*\*\*

## **推荐系统**

\*\*\*\*![](https://pic1.zhimg.com/80/v2-5e049bcd16aa9a33f90e548519f777dc_720w.jpg)

**百科数据**

**维基百科**

维基百科会定时将语料库打包发布：

数据处理博客

https://dumps.wikimedia.org/zhwiki/

**百度百科**

只能自己爬，爬取得链接：https://pan.baidu.com/share/init?surl=i3wvfil提取码 neqs 。

## **指代消歧**

CoNLL 2012 ：http://conll.cemantix.org/2012/data.html

## \*\*\*\*

**上百种预训练中文词向量**

https://github.com/Embedding/Chinese-Word-Vectors

**中文完形填空数据集**

https://github.com/ymcui/Chinese-RC-Dataset

**中华古诗词数据库**

最全中华古诗词数据集，唐宋两朝近一万四千古诗人, 接近5.5万首唐诗加26万宋诗. 两宋时期1564位词人，21050首词。

https://github.com/chinese-poetry/chinese-poetry

**保险行业语料库**

https://github.com/Samurais/insuranceqa-corpus-zh

**汉语拆字字典**

英文可以做char embedding，中文不妨可以试试拆字

https://github.com/kfcd/chaizi

**中文数据集平台**

**搜狗实验室**

搜狗实验室提供了一些高质量的中文文本数据集，时间比较早，多为2012年以前的数据。

[https://www.sogou.com/labs/resource/list\_pingce.php](https://link.zhihu.com/?target=https%3A//www.sogou.com/labs/resource/list_pingce.php)

**中科大自然语言处理与信息检索共享平台**

[http://www.nlpir.org/?action-category-catid-28](https://link.zhihu.com/?target=http%3A//www.nlpir.org/%3Faction-category-catid-28)

**中文语料小数据**

包含了中文命名实体识别、中文关系识别、中文阅读理解等一些小量数据。

[https://github.com/crownpku/Small-Chinese-Corpus](https://link.zhihu.com/?target=https%3A//github.com/crownpku/Small-Chinese-Corpus)

**维基百科数据集**

{% embed url="https://dumps.wikimedia.org/" %}





### 语料库\(CLUECorpus2020\)：语言建模、预训练或生成型任务

Corpus for Langauge Modelling, Pre-training, Generating tasks

可用于语言建模、预训练或生成型任务等，数据量超过14G，近4000个定义良好的txt文件、50亿个字。主要部分来自于[nlp\_chinese\_corpus项目](https://github.com/brightmart/nlp_chinese_corpus)

当前语料库按照【预训练格式】处理，内含有多个文件夹；每个文件夹有许多不超过4M大小的小文件，文件格式符合预训练格式：每句话一行，文档间空行隔开。

包含如下子语料库（总共14G语料）：

1、[新闻语料 news2016zh\_corpus](https://pan.baidu.com/s/195M7H5w3N8shYlqCjVL0_Q): 8G语料，分成两个上下两部分，总共有2000个小文件。 密码:mzlk

2、[社区互动-语料 webText2019zh\_corpus](https://pan.baidu.com/s/1Vk2PihMiZNmWvA2agPb1iA)：3G语料，包含3G文本，总共有900多个小文件。 密码:qvlq

3、[维基百科-语料 wiki2019zh\_corpus](https://pan.baidu.com/s/1XrM-x70PY4JEb0xCoB_mUw)：1.1G左右文本，包含300左右小文件。 密码:rja4

4、[评论数据-语料 comments2019zh\_corpus](https://pan.baidu.com/s/16cPwCcPduMNGdRSuILhEuQ)：2.3G左右文本，共784个小文件，包括点评评论547个、亚马逊评论227个，合并[ChineseNLPCorpus](https://github.com/InsaneLife/ChineseNLPCorpus)的多个评论数据，清洗、格式转换、拆分成小文件。 密码:5kwk

这些语料，你可以通过上面这两个项目，清洗数据并做格式转换获得；

你也可以通过邮件申请（chineseGLUE\#163.com）获得单个项目的语料，告知单位或学校、姓名、语料用途；

如需获得ChineseGLUE项目下的所有语料，需成为ChineseGLUE组织成员，并完成一个（小）任务。

### CLUE benchmark的定位 Vision

为更好的服务中文语言理解、任务和产业界，做为通用语言模型测评的补充，通过完善中文语言理解基础设施的方式来促进中文语言模型的发展

### 数据集介绍与下载 Introduction of datasets

[提交样例下载](https://storage.googleapis.com/cluebenchmark/tasks/clue_submit_examples.zip)

**1. AFQMC 蚂蚁金融语义相似度 Ant Financial Question Matching Corpus**

```text
     数据量：训练集（34334）验证集（4316）测试集（3861）
     例子：
     {"sentence1": "双十一花呗提额在哪", "sentence2": "里可以提花呗额度", "label": "0"}
     每一条数据有三个属性，从前往后分别是 句子1，句子2，句子相似度标签。其中label标签，1 表示sentence1和sentence2的含义类似，0表示两个句子的含义不同。
```

[AFQMC'数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/afqmc_public.zip)

**2.TNEWS' 今日头条中文新闻（短文本）分类 Short Text Classificaiton for News**

该数据集来自今日头条的新闻版块，共提取了15个类别的新闻，包括旅游，教育，金融，军事等。

```text
     数据量：训练集(53,360)，验证集(10,000)，测试集(10,000)
     例子：
     {"label": "102", "label_des": "news_entertainment", "sentence": "江疏影甜甜圈自拍，迷之角度竟这么好看，美吸引一切事物"}
     每一条数据有三个属性，从前往后分别是 分类ID，分类名称，新闻字符串（仅含标题）。
```

[TNEWS'数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/tnews_public.zip)

**3.IFLYTEK' 长文本分类 Long Text classification**

该数据集共有1.7万多条关于app应用描述的长文本标注数据，包含和日常生活相关的各类应用主题，共119个类别："打车":0,"地图导航":1,"免费WIFI":2,"租车":3,….,"女性":115,"经营":116,"收款":117,"其他":118\(分别用0-118表示\)。

```text
    数据量：训练集(12,133)，验证集(2,599)，测试集(2,600)
    例子：
    {"label": "110", "label_des": "社区超市", "sentence": "朴朴快送超市创立于2016年，专注于打造移动端30分钟即时配送一站式购物平台，商品品类包含水果、蔬菜、肉禽蛋奶、海鲜水产、粮油调味、酒水饮料、休闲食品、日用品、外卖等。朴朴公司希望能以全新的商业模式，更高效快捷的仓储配送模式，致力于成为更快、更好、更多、更省的在线零售平台，带给消费者更好的消费体验，同时推动中国食品安全进程，成为一家让社会尊敬的互联网公司。,朴朴一下，又好又快,1.配送时间提示更加清晰友好2.保障用户隐私的一些优化3.其他提高使用体验的调整4.修复了一些已知bug"}
    每一条数据有三个属性，从前往后分别是 类别ID，类别名称，文本内容。
```

[IFLYTEK'数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/iflytek_public.zip)

**4.CMNLI 语言推理任务 Chinese Multi-Genre NLI**

CMNLI数据由两部分组成：XNLI和MNLI。数据来自于fiction，telephone，travel，government，slate等，对原始MNLI数据和XNLI数据进行了中英文转化，保留原始训练集，合并XNLI中的dev和MNLI中的matched作为CMNLI的dev，合并XNLI中的test和MNLI中的mismatched作为CMNLI的test，并打乱顺序。该数据集可用于判断给定的两个句子之间属于蕴涵、中立、矛盾关系。

```text
    数据量：train(391,782)，dev(12,426)，test(13,880)
    例子：
    {"sentence1": "新的权利已经足够好了", "sentence2": "每个人都很喜欢最新的福利", "label": "neutral"}
    每一条数据有三个属性，从前往后分别是 句子1，句子2，蕴含关系标签。其中label标签有三种：neutral，entailment，contradiction。
```

[CMNLI数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/cmnli_public.zip)

**5. WSC Winograd模式挑战中文版 The Winograd Schema Challenge,Chinese Version**

威诺格拉德模式挑战赛是图灵测试的一个变种，旨在判定AI系统的常识推理能力。参与挑战的计算机程序需要回答一种特殊但简易的常识问题：代词消歧问题，即对给定的名词和代词判断是否指代一致。

```text
数据量：训练集(532)，验证集(104)，测试集(143) 
例子：
{"target": 
    {"span2_index": 28, 
     "span1_index": 0, 
     "span1_text": "马克", 
     "span2_text": "他"
    }, 
     "idx": 0, 
     "label": "false", 
     "text": "马克告诉皮特许多关于他自己的谎言，皮特也把这些谎言写进了他的书里。他应该多怀疑。"
}
    其中label标签，true表示指代一致，false表示指代不一致。
```

[WSC数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/wsc_public.zip)

**6. CSL 论文关键词识别 Keyword Recognition**

[中文科技文献数据集\(CSL\)](https://github.com/P01son6415/chinese-scientific-literature-dataset)取自中文论文摘要及其关键词，论文选自部分中文社会科学和自然科学核心期刊。 使用tf-idf生成伪造关键词与论文真实关键词混合，构造摘要-关键词对，任务目标是根据摘要判断关键词是否全部为真实关键词。

```text
    数据量：训练集(20,000)，验证集(3,000)，测试集(3,000)
    例子： 
    {"id": 1, "abst": "为解决传统均匀FFT波束形成算法引起的3维声呐成像分辨率降低的问题,该文提出分区域FFT波束形成算法.远场条件下,以保证成像分辨率为约束条件,以划分数量最少为目标,采用遗传算法作为优化手段将成像区域划分为多个区域.在每个区域内选取一个波束方向,获得每一个接收阵元收到该方向回波时的解调输出,以此为原始数据在该区域内进行传统均匀FFT波束形成.对FFT计算过程进行优化,降低新算法的计算量,使其满足3维成像声呐实时性的要求.仿真与实验结果表明,采用分区域FFT波束形成算法的成像分辨率较传统均匀FFT波束形成算法有显著提高,且满足实时性要求.", "keyword": ["水声学", "FFT", "波束形成", "3维成像声呐"], "label": "1"}
    每一条数据有四个属性，从前往后分别是 数据ID，论文摘要，关键词，真假标签。
    
```

[CSL数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/csl_public.zip)

**7.CMRC2018 简体中文阅读理解任务 Reading Comprehension for Simplified Chinese**

[https://hfl-rc.github.io/cmrc2018/](https://hfl-rc.github.io/cmrc2018/)

```text
数据量：训练集(短文数2,403，问题数10,142)，试验集(短文数256，问题数1,002)，开发集(短文数848，问题数3,219)  
例子：
{
  "version": "1.0",
  "data": [
    {
        "title": "傻钱策略",
        "context_id": "TRIAL_0",
        "context_text": "工商协进会报告，12月消费者信心上升到78.1，明显高于11月的72。另据《华尔街日报》报道，2013年是1995年以来美国股市表现最好的一年。这一年里，投资美国股市的明智做法是追着“傻钱”跑。所谓的“傻钱”策略，其实就是买入并持有美国股票这样的普通组合。这个策略要比对冲基金和其它专业投资者使用的更为复杂的投资方法效果好得多。",
        "qas":[
                {
                "query_id": "TRIAL_0_QUERY_0",
                "query_text": "什么是傻钱策略？",
                "answers": [
                     "所谓的“傻钱”策略，其实就是买入并持有美国股票这样的普通组合",
                     "其实就是买入并持有美国股票这样的普通组合",
                     "买入并持有美国股票这样的普通组合"
                    ]
                },
                {
                "query_id": "TRIAL_0_QUERY_1",
                "query_text": "12月的消费者信心指数是多少？",
                "answers": [
                    "78.1",
                    "78.1",
                    "78.1"
                    ]
                },
                {
                "query_id": "TRIAL_0_QUERY_2",
                "query_text": "消费者信心指数由什么机构发布？",
                "answers": [
                    "工商协进会",
                    "工商协进会",
                    "工商协进会"
                    ]
                }
            ]
        }
    ]
}
```

[CMRC2018数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/cmrc2018_public.zip)

**8.DRCD 繁体阅读理解任务 Reading Comprehension for Traditional Chinese**

台達閱讀理解資料集 Delta Reading Comprehension Dataset \(DRCD\)\([https://github.com/DRCKnowledgeTeam/DRCD](https://github.com/DRCKnowledgeTeam/DRCD)\) 屬於通用領域繁體中文機器閱讀理解資料集。 本資料集期望成為適用於遷移學習之標準中文閱讀理解資料集。

```text
数据量：训练集(8,016个段落，26,936个问题)，验证集(1,000个段落，3,524个问题)，测试集(1,000个段落，3,493个问题)  
例子：
{
  "version": "1.3",
  "data": [
    {
      "title": "基督新教",
      "id": "2128",
      "paragraphs": [
        {
          "context": "基督新教與天主教均繼承普世教會歷史上許多傳統教義，如三位一體、聖經作為上帝的啟示、原罪、認罪、最後審判等等，但有別於天主教和東正教，新教在行政上沒有單一組織架構或領導，而且在教義上強調因信稱義、信徒皆祭司， 以聖經作為最高權威，亦因此否定以教宗為首的聖統制、拒絕天主教教條中關於聖傳與聖經具同等地位的教導。新教各宗派間教義不盡相同，但一致認同五個唯獨：唯獨恩典：人的靈魂得拯救唯獨是神的恩典，是上帝送給人的禮物。唯獨信心：人唯獨藉信心接受神的赦罪、拯救。唯獨基督：作為人類的代罪羔羊，耶穌基督是人與上帝之間唯一的調解者。唯獨聖經：唯有聖經是信仰的終極權威。唯獨上帝的榮耀：唯獨上帝配得讚美、榮耀",
          "id": "2128-2",
          "qas": [
            {
              "id": "2128-2-1",
              "question": "新教在教義上強調信徒皆祭司以及什麼樣的理念?",
              "answers": [
                {
                  "id": "1",
                  "text": "因信稱義",
                  "answer_start": 92
                }
              ]
            },
            {
              "id": "2128-2-2",
              "question": "哪本經典為新教的最高權威?",
              "answers": [
                {
                  "id": "1",
                  "text": "聖經",
                  "answer_start": 105
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}
```

数据格式和squad相同，如果使用简体中文模型进行评测的时候可以将其繁转简\(本项目已提供\) [DRCD2018数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/drcd_public.zip)

**9.ChID 成语阅读理解填空 Chinese IDiom Dataset for Cloze Test**

[https://arxiv.org/abs/1906.01265](https://arxiv.org/abs/1906.01265)  
成语完形填空，文中多处成语被mask，候选项中包含了近义的成语。

```text
    数据量：训练集(84,709)，验证集(3,218)，测试集(3,231)
    例子：
    {
      "content": [
        # 文段0
        "……在热火22年的历史中，他们已经100次让对手得分在80以下，他们在这100次中都取得了胜利，今天他们希望能#idiom000378#再进一步。", 
        # 文段1
        "在轻舟发展过程之中，是和业内众多企业那样走相似的发展模式，去#idiom000379#？还是迎难而上，另走一条与众不同之路。诚然，#idiom000380#远比随大流更辛苦，更磨难，更充满风险。但是有一条道理却是显而易见的：那就是水往低处流，随波逐流，永远都只会越走越低。只有创新，只有发展科技，才能强大自己。", 
        # 文段2
        "最近十年间，虚拟货币的发展可谓#idiom000381#。美国著名经济学家林顿·拉鲁什曾预言：到2050年，基于网络的虚拟货币将在某种程度上得到官方承认，成为能够流通的货币。现在看来，这一断言似乎还嫌过于保守……", 
        # 文段3
        "“平时很少能看到这么多老照片，这次图片展把新旧照片对比展示，令人印象深刻。”现场一位参观者对笔者表示，大多数生活在北京的人都能感受到这个城市#idiom000382#的变化，但很少有人能具体说出这些变化，这次的图片展按照区域发展划分，展示了丰富的信息，让人形象感受到了60年来北京的变化和发展。", 
        # 文段4
        "从今天大盘的走势看，市场的热点在反复的炒作之中，概念股的炒作#idiom000383#，权重股走势较为稳健，大盘今日早盘的震荡可以看作是多头关前的蓄势行为。对于后市，大盘今日蓄势震荡后，明日将会在权重和题材股的带领下亮剑冲关。再创反弹新高无悬念。", 
        # 文段5
        "……其中，更有某纸媒借尤小刚之口指出“根据广电总局的这项要求，2009年的荧屏将很难出现#idiom000384#的情况，很多已经制作好的非主旋律题材电视剧想在卫视的黄金时段播出，只能等到2010年了……"],
      "candidates": [
        "百尺竿头", 
        "随波逐流", 
        "方兴未艾", 
        "身体力行", 
        "一日千里", 
        "三十而立", 
        "逆水行舟", 
        "日新月异", 
        "百花齐放", 
        "沧海一粟"
      ]
    }
```

[CHID数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/chid_public.zip)

**10.C3 中文多选阅读理解 Multiple-Choice Chinese Machine Reading Comprehension**

[https://arxiv.org/abs/1904.09679](https://arxiv.org/abs/1904.09679)  
中文多选阅读理解数据集，包含对话和长文等混合类型数据集。训练和验证集中的d,m分别代表对话、多种文本类型混合。

```text
    数据量：训练集(11,869)，验证集(3,816)，测试集(3,892)
    例子：
    [
      [
        "男：你今天晚上有时间吗?我们一起去看电影吧?",
        "女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……"
      ],
      [
       {
        "question": "女的最喜欢哪种电影?",
        "choice": [
         "恐怖片",
         "爱情片",
         "喜剧片",
         "科幻片"
        ],
        "answer": "喜剧片"
       }
      ],
    "25-35"
    ],
    [
      [
       "男：足球比赛是明天上午八点开始吧?",
       "女：因为天气不好，比赛改到后天下午三点了。"
      ],
      [
       {
        "question": "根据对话，可以知道什么?",
        "choice": [
         "今天天气不好",
         "比赛时间变了",
         "校长忘了时间"
        ],
        "answer": "比赛时间变了"
       }
      ],
    "31-109"
    ]
```

[C3数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/c3_public.zip)

**11. 诊断集 CLUE\_diagnostics test\_set**

诊断集，用于评估不同模型在9种语言学家总结的中文语言现象上的表现

使用在CMNLI上训练过的模型，直接预测在这个诊断集上的结果，提交格式和CMNLI一致，在排行榜详情页可以看到结果

[diagnostics数据集下载](https://storage.googleapis.com/cluebenchmark/tasks/clue_diagnostics_public.zip)

**更多数据集添加中，Comming soon!**

如果你有定义良好的数据集并愿意为社区做贡献，请与我们取得联系 ChineseGLUE\#163.com

**数据集整体下载**

[整体下载 Comining Soon](https://github.com/CLUEbenchmark/CLUE#)最近几天，会添加中

或使用命令：wget

Data filter method

### 难样本数据集筛选方法

为了增加模型区分度和增大数据集难度，我们采用**k折交叉验证**的方式对v0版本的数据集进行过滤，最终得到v1版本。

```text
具体步骤：
1.将特定任务的数据集集中在一起，同时选择一个基准测试模型（如AlbertTiny）
2.将数据集均匀分成k份；每次选择其中1份当验证集，剩下的都作为训练集，训练基准模型并在验证集上测试、保留预测结果
3.重复步骤二k次，让每一份数据都有机会当验证集，过完整个数据集
4.将k份验证集的预测结果合并；保留其中预测错误的样本（可以认为是较难的数据），并删除一部分预测正确的样本。最后重新划分出训练集、验证集、测试集
5.如果希望进一步筛选难样本，重复步骤2-4即可
```

Notes：

```text
1.k一般选择4-6
2.难样本，是指在交叉验证过程中模型预测错误的样本，也是我们希望尽可能保留的样本。模型预测正确的样本最终会被优先排除一部分
```

\*\*\*\*

