# BERT/ELMO/词向量

## **预训练：（词向量or模型）**

**BERT**

开源代码：https://github.com/google-research/bert

模型下载：BERT-Base, Chinese: Chinese Simplified and Traditional, 12-layer, 768-hidden, 12-heads, 110M parameters

**ELMO**

开源代码：https://github.com/allenai/bilm-tf

预训练的模型：https://allennlp.org/elmo

**腾讯词向量**

腾讯AI实验室公开的中文词向量数据集包含800多万中文词汇，其中每个词对应一个200维的向量。

下载地址：https://ai.tencent.com/ailab/nlp/embedding.html

